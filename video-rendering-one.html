<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Video Rendering One - Manual Frame Update</title>
  </head>
  <body>
    <canvas id="canvas" width="640" height="480"></canvas>
  </body>
  <script src="./utils/utils.js"></script>
  <script src="./toji-gl-matrix/gl-matrix.js"></script>
  <script id="shader" type="wgsl">
    // Vertex Shader

    @group(0) @binding(0)
    var<uniform> transform: mat4x4<f32>;
    @group(0) @binding(1)
    var<uniform> projection: mat4x4<f32>;

    struct VertexOutput {
      @builtin(position) clip_position: vec4<f32>,
      @location(0) tex_coords: vec2<f32>,
    };

    @vertex
    fn vs_main(
      @location(0) inPos: vec3<f32>,
      @location(1) inTexCoords: vec2<f32>
    ) -> VertexOutput {
      var out: VertexOutput;
      out.clip_position = projection * transform * vec4<f32>(inPos, 1.0);
      out.tex_coords = inTexCoords;
      return out;
    }

    // Fragment Shader

    @group(0) @binding(2)
    var t_diffuse: texture_2d<f32>;
    @group(0) @binding(3)
    var s_diffuse: sampler;

    @fragment
    fn fs_main(in: VertexOutput) -> @location(0) vec4<f32> {
      return textureSampleLevel(t_diffuse, s_diffuse, in.tex_coords, 0);
    }
  </script>
  <script>
    let copyVideo = false;
    let videoTag = null;

    function setupVideo(url) {
      const video = document.createElement("video");

      let playing = false;
      let timeUpdate = false;

      video.playsInline = true;
      video.muted = true;
      video.loop = true;

      // Waiting for these 2 events ensures
      // there is data in the video

      video.addEventListener(
        "playing",
        () => {
          playing = true;
          checkReady();
        },
        true
      );

      video.addEventListener(
        "timeUpdate",
        () => {
          timeUpdate = true;
          checkReady();
        },
        true
      );

      video.src = url;
      video.play();

      function checkReady() {
        if (playing && timeUpdate) {
          copyVideo = true;
        }
      }

      return video;
    }

    async function webgpu() {
      const adapter = await navigator.gpu.requestAdapter();
      let device = await adapter.requestDevice();

      const context = configContext(device, canvas);

      // Create Shaders
      const textureDesc = {
        size: { width: videoTag.videoWidth, height: videoTag.videoHeight },
        format: "rgba8unorm",
        usage:
          GPUTextureUsage.TEXTURE_BINDING |
          GPUTextureUsage.COPY_DST |
          GPUTextureUsage.RENDER_ATTACHMENT,
      };

      const texture = device.createTexture(textureDesc);

      videoTag.ontimeupdate = async (event) => {
        let imageData = await createImageBitmap(videoTag);

        device.queue.copyExternalImageToTexture(
          { source: imageData },
          { texture },
          textureDesc.size
        );
      };

      const sampler = device.createSampler({
        addressModeU: "repeat",
        addressModeV: "repeat",
        magFilter: "linear",
        minFilter: "linear",
        mipmapFilter: "linear",
      });

      let shaderModule = shaderModuleFromCode(device, "shader");

      const positionAttribDesc = {
        shaderLocation: 0, // @location(0)
        offset: 0,
        format: "float32x3",
      };

      const positionBufferLayoutDesc = {
        attributes: [positionAttribDesc],
        arrayStride: 4 * 3, // sizeof(float) * 3
        stepMode: "vertex",
      };

      const texCoordsAttribDesc = {
        shaderLocation: 1, // @location(1)
        offset: 0,
        format: "float32x2",
      };

      const texCoordsBufferLayoutDesc = {
        attributes: [texCoordsAttribDesc],
        arrayStride: 4 * 2, // sizeof(float) * 2
        stepMode: "vertex",
      };

      const positions = new Float32Array([
        100.0, -100.0, 0.0, 100.0, 100.0, 0.0, -100.0, -100.0, 0.0, -100.0,
        100.0, 0.0,
      ]);

      const positionBuffer = createGPUBuffer(
        device,
        positions,
        GPUBufferUsage.VERTEX
      );

      const texCoords = new Float32Array([
        1.0, 0.0,
        //
        1.0, 1.0, 0.0, 0.0, 0.0, 1.0,
      ]);

      let texCoordsBuffer = createGPUBuffer(
        device,
        texCoords,
        GPUBufferUsage.VERTEX
      );

      let translateMatrix = glMatrix.mat4.lookAt(
        glMatrix.mat4.create(),
        glMatrix.vec3.fromValues(100, 100, 100),
        glMatrix.vec3.fromValues(0, 0, 0),
        glMatrix.vec3.fromValues(0.0, 0.0, 1.0)
      );

      let projectionMatrix = glMatrix.mat4.perspective(
        glMatrix.mat4.create(),
        1.4,
        640.0 / 480.0,
        0.1,
        1000.0
      );

      let translateMatrixUniformBuffer = createGPUBuffer(
        device,
        translateMatrix,
        GPUBufferUsage.UNIFORM
      );

      let projectionMatrixUniformBuffer = createGPUBuffer(
        device,
        projectionMatrix,
        GPUBufferUsage.UNIFORM
      );

      let uniformBindGroupLayout = device.createBindGroupLayout({
        entries: [
          {
            binding: 0,
            visibility: GPUShaderStage.VERTEX,
            buffer: {},
          },
          {
            binding: 1,
            visibility: GPUShaderStage.VERTEX,
            buffer: {},
          },
          {
            binding: 2,
            visibility: GPUShaderStage.FRAGMENT,
            texture: {},
          },
          {
            binding: 3,
            visibility: GPUShaderStage.FRAGMENT,
            sampler,
          },
        ],
      });

      const pipelineLayoutDesc = {
        bindGroupLayouts: [uniformBindGroupLayout],
      };

      const layout = device.createPipelineLayout(pipelineLayoutDesc);

      const colorState = {
        format: "bgra8unorm",
      };

      const pipelineDesc = {
        layout,
        vertex: {
          module: shaderModule,
          entryPoint: "vs_main",
          buffers: [positionBufferLayoutDesc, texCoordsBufferLayoutDesc],
        },
        fragment: {
          module: shaderModule,
          entryPoint: "fs_main",
          targets: [colorState],
        },
        primitive: {
          topology: "triangle-strip",
          frontFace: "ccw",
          cullMode: "none",
        },
      };

      pipeline = device.createRenderPipeline(pipelineDesc);

      let uniformBindGroup = device.craeteBindGroup({
        layout: uniformBindGroupLayout,
        entries: [
          {
            binding: 0,
            resource: {
              buffer: translateMatrixUniformBuffer,
            },
          },
          {
            binding: 1,
            resource: {
              buffer: projectionMatrixUniformBuffer,
            },
          },
          {
            binding: 2,
            resource: texture.createView(),
          },
          {
            binding: 3,
            resource: sampler,
          },
        ],
      });

      function render() {
        requestAnimationFrame(render);

        if (copyVideo) {
          let colorTexture = context.getCurrentTexture();
          let colorTextureView = colorTexture.createView();

          let colorAttachment = {
            view: colorTextureView,
            clearValue: { r: 1, g: 0, b: 0, a: 1 },
            loadOp: "clear",
            storeOp: "store",
          };

          const renderPassDesc = {
            colorAttachments: [colorAttachment],
          };

          commandEncoder = device.createCommandEncoder();
          passEncoder = commandEncoder.beginRenderPass(renderPassDesc);

          passEncoder.setViewport(0, 0, canvas.width, canvas.height, 0, 1);
          passEncoder.setPipeline(pipeline);
          passEncoder.setBindGroup(0, uniformBindGroup);
          passEncoder.setVertexBuffer(0, positionBuffer);
          passEncoder.setVertexBuffer(1, texCoordsBuffer);
          passEncoder.draw(4, 1);
          passEncoder.end();

          device.queue.submit([commandEncoder.finish()]);
        }
      }

      requestAnimationFrame(render);
    }

    videoTag = setupVideo("./data/Firefox.mp4");

    (async () => {
      return new Promise((resolve) => {
        let timer = setInterval(() => {
          if (copyVideo) {
            clearInterval(timer);
            resolve();
          }
        }, 300);
      });
    })().then(() => {
      webgpu();
    });
  </script>
</html>
